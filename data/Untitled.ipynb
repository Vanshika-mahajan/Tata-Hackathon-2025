{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda87e30-fddb-42e6-8124-f8c558346ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Road network graph loaded for LLM integration.\n",
      "Aligned EV stations data loaded for LLM integration.\n",
      "\n",
      "--- Testing LLM-based Natural Language Understanding (NLU) ---\n",
      "An unexpected error occurred during LLM interaction: model requires more system memory (5.6 GiB) than is available (3.3 GiB) (status code: 500)\n",
      "\n",
      "Query 1 Parsed Parameters: {'error': 'LLM interaction failed: model requires more system memory (5.6 GiB) than is available (3.3 GiB) (status code: 500)'}\n",
      "An unexpected error occurred during LLM interaction: model requires more system memory (5.6 GiB) than is available (3.3 GiB) (status code: 500)\n",
      "\n",
      "Query 2 Parsed Parameters: {'error': 'LLM interaction failed: model requires more system memory (5.6 GiB) than is available (3.3 GiB) (status code: 500)'}\n",
      "An unexpected error occurred during LLM interaction: model requires more system memory (5.6 GiB) than is available (3.3 GiB) (status code: 500)\n",
      "\n",
      "Query 3 Parsed Parameters: {'error': 'LLM interaction failed: model requires more system memory (5.6 GiB) than is available (3.3 GiB) (status code: 500)'}\n",
      "An unexpected error occurred during LLM interaction: model requires more system memory (5.6 GiB) than is available (3.3 GiB) (status code: 500)\n",
      "\n",
      "Query 4 Parsed Parameters: {'error': 'LLM interaction failed: model requires more system memory (5.6 GiB) than is available (3.3 GiB) (status code: 500)'}\n",
      "\n",
      "--- LLM Integration (NLU) step complete. ---\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json # To work with JSON output from LLM\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Re-Load necessary data (if kernel restarted or running this cell independently) ---\n",
    "data_folder = ''\n",
    "graph_file_path = os.path.join(data_folder, \"road_network_Delhi_India.graphml\")\n",
    "# Ensure osmnx is loaded with the correct version (1.2.0)\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "try:\n",
    "    # We explicitly load the graph here\n",
    "    G = ox.load_graphml(filepath=graph_file_path)\n",
    "    print(\"Road network graph loaded for LLM integration.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading graph for LLM integration: {e}\")\n",
    "    print(\"Please ensure the graph was saved correctly in Step 4 and path is accurate.\")\n",
    "    exit()\n",
    "\n",
    "aligned_ev_file_path = os.path.join(data_folder, 'aligned_ev_stations.csv')\n",
    "try:\n",
    "    df_stations = pd.read_csv(aligned_ev_file_path)\n",
    "    # Ensure 'nearest_node' is int type\n",
    "    df_stations['nearest_node'] = df_stations['nearest_node'].astype(int)\n",
    "    print(\"Aligned EV stations data loaded for LLM integration.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading aligned EV stations for LLM integration: {e}\")\n",
    "    print(\"Please ensure aligned_ev_stations.csv was saved correctly in Step 5 and path is accurate.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Define LLM Interaction Function ---\n",
    "def get_trip_parameters_from_llm(user_query):\n",
    "    \"\"\"\n",
    "    Uses the local Ollama LLM to extract structured trip parameters from a user query.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): The natural language query from the user (e.g., \"Plan a trip from Delhi to Noida\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing 'origin', 'destination', 'ev_model' (or None if not found),\n",
    "              or an error message.\n",
    "    \"\"\"\n",
    "    # Define the prompt for the LLM. This is crucial for guiding its output.\n",
    "    # We instruct it to output JSON for easy parsing.\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant that helps extract trip information from user queries for an EV journey planner.\n",
    "    Your task is to identify the ORIGIN, DESTINATION, and optionally the EV_MODEL.\n",
    "    If an EV_MODEL is not mentioned, use \"Tata Nexon EV\" as the default.\n",
    "    If you cannot identify a clear origin or destination, state \"incomplete_query\".\n",
    "\n",
    "    Respond ONLY with a JSON object. Do NOT include any other text or markdown outside the JSON.\n",
    "\n",
    "    Example 1:\n",
    "    User: \"Plan a trip from Connaught Place to Noida Sec 62 for my Tata Tiago EV.\"\n",
    "    JSON: {{\"origin\": \"Connaught Place, Delhi\", \"destination\": \"Noida Sec 62\", \"ev_model\": \"Tata Tiago EV\"}}\n",
    "\n",
    "    Example 2:\n",
    "    User: \"I want to travel from Mumbai to Pune.\"\n",
    "    JSON: {{\"origin\": \"Mumbai\", \"destination\": \"Pune\", \"ev_model\": \"Tata Nexon EV\"}}\n",
    "\n",
    "    Example 3:\n",
    "    User: \"Find charging stations near Connaught Place.\"\n",
    "    JSON: {{\"origin\": \"Connaught Place, Delhi\", \"destination\": \"Connaught Place, Delhi\", \"ev_model\": \"Tata Nexon EV\", \"intent\": \"find_stations\"}}\n",
    "\n",
    "    Example 4:\n",
    "    User: \"What's the best route?\"\n",
    "    JSON: {{\"origin\": null, \"destination\": null, \"ev_model\": null, \"error\": \"incomplete_query\"}}\n",
    "\n",
    "    User Query: \"{user_query}\"\n",
    "    JSON:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Call the local Ollama model\n",
    "        response = ollama.chat(model='phi3', messages=[\n",
    "            {'role': 'system', 'content': prompt},\n",
    "            {'role': 'user', 'content': user_query}\n",
    "        ], options={'temperature': 0.1}) # Use lower temperature for more predictable output\n",
    "\n",
    "        # Extract the content from the response\n",
    "        llm_response_content = response['message']['content'].strip()\n",
    "        print(f\"LLM Raw Response: \\n{llm_response_content}\")\n",
    "\n",
    "        # Try to parse the JSON response\n",
    "        parsed_json = json.loads(llm_response_content)\n",
    "        return parsed_json\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing LLM response as JSON: {e}\")\n",
    "        print(f\"Problematic content: {llm_response_content}\")\n",
    "        return {\"error\": \"LLM response not valid JSON. Please try again or refine prompt.\"}\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during LLM interaction: {e}\")\n",
    "        return {\"error\": f\"LLM interaction failed: {e}\"}\n",
    "\n",
    "# --- Test the LLM Integration ---\n",
    "print(\"\\n--- Testing LLM-based Natural Language Understanding (NLU) ---\")\n",
    "\n",
    "# Test Query 1: Basic trip planning\n",
    "query_1 = \"I want to drive from Dilli Haat to Qutub Minar in my Tata Punch EV.\"\n",
    "params_1 = get_trip_parameters_from_llm(query_1)\n",
    "print(f\"\\nQuery 1 Parsed Parameters: {params_1}\")\n",
    "\n",
    "# Test Query 2: Missing EV model, default should be applied\n",
    "query_2 = \"What is the best route from Red Fort to India Gate?\"\n",
    "params_2 = get_trip_parameters_from_llm(query_2)\n",
    "print(f\"\\nQuery 2 Parsed Parameters: {params_2}\")\n",
    "\n",
    "# Test Query 3: Incomplete query\n",
    "query_3 = \"Just tell me about routes.\"\n",
    "params_3 = get_trip_parameters_from_llm(query_3)\n",
    "print(f\"\\nQuery 3 Parsed Parameters: {params_3}\")\n",
    "\n",
    "# Test Query 4: Find stations intent\n",
    "query_4 = \"Find free charging stations near South Extension market.\"\n",
    "params_4 = get_trip_parameters_from_llm(query_4)\n",
    "print(f\"\\nQuery 4 Parsed Parameters: {params_4}\")\n",
    "\n",
    "print(\"\\n--- LLM Integration (NLU) step complete. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdcffa2-3d95-4651-b141-351e59b49406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tata EV Nav Hackathon (Python 3.11)",
   "language": "python",
   "name": "tata_ev_nav_hackathon_py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
